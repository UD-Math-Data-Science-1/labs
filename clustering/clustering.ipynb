{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"clustering.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "SEED = 3383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data preparation\n",
    "\n",
    "We will load a dataset from [voteview.com](https://voteview.com), which tabulates the roll-call vote of every session of the U.S. Congress. Here, we load all of the votes cast by senators between the 91st and 111th sessions of Congress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate = pd.read_csv(\"senate_votes.csv\")\n",
    "senate.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rollnumber` is a serial number of the bill or resolution that was voted on, and `icpsr` is a unique identifier for everyone who has ever served in Congress.\n",
    "\n",
    "Without going into parliamentary details, there are three codes that mean a \"yea\" vote and three that mean \"nay.\" We will encode these as +1 and -1, respectively, and anything else is a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_type(v):\n",
    "    if v in [1,2,3]: return 1\n",
    "    elif v in [4,5,6]: return -1\n",
    "    else: return 0\n",
    "\n",
    "senate[\"vote\"] = senate[\"cast_code\"].apply(vote_type)\n",
    "senate.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the voting records, we will also access to the party affiliations of the individual senators. This information is loaded from a separate file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv(\"HSall_members.csv\").set_index(\"icpsr\")\n",
    "members.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There have been over 50 political parties for senators over U.S. history, as encoded by `party_code` above. For modern times, we want to identify the two major parties and label all the others as independent. By indexing a series with default value *Ind* on all the unique party codes, we only need to set the two values we care about and then make the replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_name = pd.Series(\"Ind\",index=members[\"party_code\"].unique())   # all codes are set to \"Ind\"\n",
    "party_name[100] = \"Dem\"\n",
    "party_name[200] = \"Rep\"\n",
    "members[\"party\"] = members[\"party_code\"].replace(party_name)\n",
    "\n",
    "print(members[\"party\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write a function that returns the data we need for a single session. One output is a table having the senator ID as the index, the individual roll calls as the columns, and values that are the individual votes. This is a job for the `pivot` method. Any senator with a `NaN` in the record did not serve the full session, and their row is dropped. The other output is the list of party affiliations for the senators in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session(number,senate,members):\n",
    "    votes = senate.loc[senate[\"congress\"]==number].pivot(index=\"icpsr\",columns=\"rollnumber\",values=\"vote\").dropna()\n",
    "    party = members.loc[members[\"congress\"]==number,\"party\"][votes.index]\n",
    "    # For more than one affiliation, use only the last one:\n",
    "    party = party.loc[np.bitwise_not(party.index.duplicated(keep=\"last\"))]   \n",
    "    return votes,party\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, in the 100th Congress we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X100,y100 = session(100,senate,members)\n",
    "print(\"party counts:\")\n",
    "print(y100.value_counts())\n",
    "print(\"feature matrix:\")\n",
    "X100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to view this feature matrix as a *heat map*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is the voting record of a senator. You can definitely see some dominant motifs in the rows, implying party lines. For the rest of the lab, you will investigate the extent of polarization in the Senate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1.1** For the 95th Congress, compute the distance matrix (matrix of pairwise distances between voting records) using the 2-norm. Make a histogram showing the distribution of all the distances. (Hint: use `A.flatten()` to transform any array `A` into a vector.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1.2** Repeat problem 1.1 for the 110th Congress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1.3** Party affiliations effectively define a clustering for each session. For the 95th Congress, make a violin plot showing the distribution of silhouette values for each cluster as defined by party affiliation. (You want one violin per party, although there is only one Independent senator.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1.4** Repeat problem 1.3 for the 110th Congress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "The distributions plotted above hint that there may be clusters within a session that have differing characteristics, so we may want to track the silhouette scores by cluster. They also suggest that we might want to use medians rather than means as central values, since there can be significant asymmetric outliers in the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Use k-means with $k=2$ clusters to fit the voting data for session number 95. **Make sure to initialize the clusterer with a random state equal to `SEED`.** Compute the silhouette values for all the samples; then, compute the median silhouette value in each cluster. (One option is to create a frame with all the values, and use `groupby` to get the medians.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following value should be a vector (1D array).\n",
    "median95 = ...\n",
    "\n",
    "print(\"Medians for k-means, k=2, session 95:\")\n",
    "print(median95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"kmeans-95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Repeat the calculation you did in problem 2.1 for all sessions from 91 to 111 (inclusive). For each session, add the median scores for both clusters to a frame, so that the final frame has 42 rows and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the following column names in your response.\n",
    "results_km2 = pd.DataFrame({\"session\":[],\"silhouette\":[]})\n",
    "\n",
    "\n",
    "print(\"K-means for k=2:\")\n",
    "print(results_km2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"kmeans-k=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**2.3** Plot the median silhouette scores with dots as a function of session number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "The conclusion from the k-means results is that there has been a substantial increase over time in the formation of two distinct clusters in the voting records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Repeat problem 2.2, but using agglomerative clustering with average linkage and both 2 and 3 clusters. (Note: This type of clustering does not use a random seed.) You will get 5 median values for each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the following column names in your response.\n",
    "results_agg = pd.DataFrame({\"session\":[],\"clusters\":[],\"silhouette\":[]})\n",
    "\n",
    "\n",
    "print(\"Agglomerative:\")\n",
    "print(results_agg.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"agglom-results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**3.2** Make a plot like the one in problem 2.3, but add color to the dots to designate the number of clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "The conclusion from the above results is that in every session, interpreting the records as 2 clusters is more justifiable than interpreting them as 3 clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset we can estimate a good value for $\\epsilon$ in the DBSCAN algorithm. The goal is to pick a value larger than the closest neighbors but smaller than cases you would not consider to be similar. Let's use a benchmark of similarity as voting identically at least 80% of the time. Then the difference in voting records can have at most $0.2V$ nonzeros, where $V$ is the number of votes taken in the session. The nonzero values are all $\\pm 2$, so the 2-norm distance between similar senators is bounded by \n",
    "\n",
    "$$\n",
    "2 \\sqrt{0.2V} \\approx 0.894 \\sqrt{V}. \n",
    "$$\n",
    "\n",
    "Our strategy will therefore be to try the values $\\epsilon = \\gamma \\sqrt{V}$, where $\\gamma=0.5,0.55,0.6,\\ldots,1.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** For session 110, set $N_\\text{min}=4$ and iterate over the values of $\\epsilon$ above to fit the voting data using DBSCAN. For each fit, record the number of non-noise clusters and the total number of noise samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the following column names in your response.\n",
    "fits_110 = pd.DataFrame({\"eps\":[],\"clusters\":[],\"noise\":[]})\n",
    "\n",
    "\n",
    "print(\"DBSCAN for session 110:\")\n",
    "print(fits_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"dbscan-110\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** For each session, use the strategy of problem 4.1 to apply DBSCAN. Among all the fits with two non-noise clusters, choose the fit that minimizes the number of noise samples, and compute the adjusted Rand index compared to the party affiliations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the following column names in your response.\n",
    "results_db = pd.DataFrame({\"session\":[],\"noise\":[],\"ARI\":[]})\n",
    "\n",
    "\n",
    "print(\"DBSCAN for all sessions:\")\n",
    "print(results_db.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"dbscan-ARI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**4.3** In two separate graphs, plot the ARI as a function of session number and the number of noise samples as a function of session number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "From the above we conclude that party affiliations have become increasingly reflective of the natural clustering behavior in voting records, and that the number of senators who do not fit well into either cluster has dropped from a substantial minority of the chamber to nearly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Select *Kernel/Restart & Run All*, then save, then run this export cell again. Submit by pushing the resulting zip file to your GitHub assignment repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f87953a4f46a7e0eea98d572fc327a848bd0e2ff64810a35c4c06ef544fb24da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('m267')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "otter": {
   "tests": {
    "agglom-results": {
     "name": "agglom-results",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert results_agg.shape==(105,3)\n",
         "failure_message": "Your result should have shape 105x3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert results_agg[\"clusters\"].astype(int).sum()==273\n",
         "failure_message": "Your result has the wrong numbers of clusters.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(results_agg[\"silhouette\"].mean(),0.2605215565306656)\n",
         "failure_message": "Your result has the wrong silhouette results.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "dbscan-110": {
     "name": "dbscan-110",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(fits_110[\"eps\"])==15\n>>> assert all(np.isclose(fits_110[\"eps\"]/np.sqrt(X110.shape[1]),np.arange(0.5,1.25,0.05)))\n",
         "failure_message": "You did not use the correct values for epsilon.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(fits_110[\"clusters\"].sum(),25)\n",
         "failure_message": "The numbers of clusters are incorrect.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(fits_110[\"noise\"].sum(),211)\n",
         "failure_message": "The numbers of clusters are incorrect.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "dbscan-ARI": {
     "name": "dbscan-ARI",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert list(results_db[\"session\"].astype(int)) == list(range(91,112))\n",
         "failure_message": "You did not get results for all of the sessions.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert results_db[\"noise\"].sum()==227\n",
         "failure_message": "You did not get the correct numbers of noise samples.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(results_db[\"ARI\"].mean(),0.7210660468410746)\n",
         "failure_message": "You did not get the correct ARI values.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "kmeans-95": {
     "name": "kmeans-95",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(median95)==np.ndarray and median95.ndim==1\n",
         "failure_message": "median95 must be a 1D array",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(np.mean(median95),0.21516807037868674)\n",
         "failure_message": "Median values are not correct.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "kmeans-k=2": {
     "name": "kmeans-k=2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(results_km2)==pd.DataFrame and results_km2.shape==(42,2) and set(results_km2.columns)==set((\"session\",\"silhouette\"))\n>>> \n",
         "failure_message": "results_km2 should be a frame with 42 rows and 2 columns.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
